{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up paths and corresponding checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths\n",
    "biburr_path = 'ComedyText/BBText.txt'\n",
    "rpryor_path = 'ComedyText/RPText.txt'\n",
    "ajesel_path = 'ComedyText/AJText.txt'\n",
    "\n",
    "allcom_path = 'ComedyText/AllComText.txt'\n",
    "\n",
    "\n",
    "path_to_ckpt = {biburr_path : \"./biburr_training\", rpryor_path : './rpryor_training', ajesel_path : './ajesel_training'}\n",
    "\n",
    "path_list = [biburr_path,rpryor_path,ajesel_path]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to randomly select model (i.e. path) trained on respective comedian 'corpus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model(model_list):\n",
    "    return random.choice(model_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.test.is_gpu_available():\n",
    "    rnn = tf.keras.layers.CuDNNGRU\n",
    "    rnn2 = tf.keras.layers.CuDNNGRU\n",
    "else:\n",
    "    import functools\n",
    "    rnn = functools.partial(\n",
    "    tf.keras.layers.GRU, recurrent_activation='sigmoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Builds model from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, \n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    rnn(rnn_units,\n",
    "        return_sequences=True, \n",
    "        recurrent_initializer='glorot_uniform',\n",
    "        stateful=True),\n",
    "\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generates text from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string,temperature=0.5):\n",
    "  # Evaluation step (generating text using the learned model)\n",
    "\n",
    "  # Number of characters to generate\n",
    "    num_generate = 2000\n",
    "\n",
    "  # Converting our start string to numbers (vectorizing) \n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "  # Low temperatures results in more predictable text.\n",
    "  # Higher temperatures results in more surprising text.\n",
    "  # Experiment to find the best setting.\n",
    "  #  temperature = .50\n",
    "\n",
    "  # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        \n",
    "      # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # using a multinomial distribution to predict the word returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.multinomial(predictions, num_samples=1)[-1,0].numpy()\n",
    "      \n",
    "      # We pass the predicted word as the next input to the model\n",
    "      # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "      \n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load  and Build Randomly Selected Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = select_model(path_list)\n",
    "\n",
    "text = open(path, 'rb').read().decode(encoding = \"utf-8\")\n",
    "vocab = sorted(set(text))\n",
    "\n",
    "\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])\n",
    "\n",
    "#Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension \n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024\n",
    "\n",
    "\n",
    "#Build and load model\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(path_to_ckpt[path]))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (1, None, 256)            19456     \n",
      "_________________________________________________________________\n",
      "cu_dnngru_2 (CuDNNGRU)       (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (1, None, 76)             77900     \n",
      "=================================================================\n",
      "Total params: 4,035,660\n",
      "Trainable params: 4,035,660\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some later. That’s what I mean? You motherfucker talking about my face. I was some come in the thing. I’m going to have to stand to be brave in the country, you know. I said, ”Oh, shit, man. I’m not going to some of them botter on What the morning. They don’t know what I’m going to me. I don’t know what is the relixed a don’t know. I said, ”I think you say, ”Goddamn it. I know you fuck with me. I was not fucking with me. She going to hell me. I ain’t gonna be all right. They’re all right there. They say shit in America shought of the been and say. “What you all right?” “A motherfucker keep the shit the good to fuck with this motherfucker. I’m gonna be the fuck along real good to me. I can’t get the shit on the beautiful. My wife looked like a dick him. You know, sometime you say, “I ain’t gonna be fuckin’ around. When I was in the real shit. I went to the boy. I got a baby’s fuckin’ around. They be talking about feeling. And the shit out of them motherfuckers was me.” “Yeah. Man. They don’t know what I mean? You know, see? You know what I mean? You know what I mean? You ever had a pitcher of the shit like that. You know. So I had a fuck. I was not the fuck alone!” And the motherfuckers know the shit on your life and shit. You know, sometime you know what I mean?” I said, ”Boy, that’s what I mean? So the time you see the shit on your shit. You know, wait, wait, wait, wait, wait, wait, wait, wait, wait, wait, wait. Shit. I had a pitcher. He’s going, ”Hey, man, I’m trying to the back on the country, she gonna do it on you. You know, you know. – Chad’s what I mean?” I said. “What? What is the motherfuckers don’t know what the motherfuckers come on the look with me. We was a bitch the shit the shit we come to me. I ain’t gonna be fucking around. Hey, man, I’m not looked at me like that. He fucked up, you know what I mean? You know, some if you see the thing. I’m gonna be fucking up it of them motherfuckers know where you say, “I’m gonna put you in the thing. I’m gonna star\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"So\",temperature=.35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComedyText/RPText.txt\n"
     ]
    }
   ],
   "source": [
    "print(path) #Reveal the source!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and generate from (known) models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bill Burr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sound like that. That dog’s so fucking stupid, you know? I just have been the whole things make me a sen. I don’t know what happened? I was like, “What’s up with a minute. I gotta get the balls to a haughter] I didn’t come from the relationship. I’m gonna do with this dog. I go, “I’m not saying that what happened? We were just saying, you know? Don’t even the most difficult job on the planet. Oh, it’s not a pit bull. It’s a fucking part of it. I think I look at it, do it, fuck it, do it, fuck it, do it, fuck it, do it, they all parents where he got it for a week, and then I go, “I’m not saying that I’m right. That’s not even figured out of your face like that. You know what I mean? It’s make an animals shit for fendy. You know what happens when I get it outta here. I’m not saying with the bast day and slaps the balls to be a mitten is gonna happen in the couch, okay? I realize that was his improvement on his childhood, and then they’re all right, all right? Do you know what happened? I was a gie for me to the greater than and go here, and then the middle of a little bit, but I was fucking that was his improvement on his catch that was his improvement on his catch that was my dad hadded be driving down the street, and I was like, “What do you mean? I love her to do and show up with a might be like… Like, I wanted to get married, and then all of a sudden, he was standing up at the dog. I got this standing up and then it all she comes up, and then I got it. There’s not heard in my girl, right? You know what I said, you know, I don’t give a fuck! Maybe you go back to your own life, right? They just look at you. Thank you. Thank you. Thank you. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Thishouldn’t be a miture out what the fuck is what happened? I was gonna get the balls to have the shit out of nowhere, but I love and start call him and then the matter and I saw this story? I just wanna slap the shit out of nowhere, he was whooping all the dick. I’ll suck your dick in the back of a man. I was l\n"
     ]
    }
   ],
   "source": [
    "text = open(biburr_path, 'rb').read().decode(encoding = \"utf-8\")\n",
    "vocab = sorted(set(text))\n",
    "\n",
    "\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])\n",
    "\n",
    "#Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension \n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024\n",
    "\n",
    "\n",
    "#Build and load model\n",
    "biburr_model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "biburr_model.load_weights(tf.train.latest_checkpoint('./biburr_training'))\n",
    "\n",
    "biburr_model.build(tf.TensorShape([1, None]))\n",
    "\n",
    "print(generate_text(biburr_model, start_string=u\"So\",temperature=.35))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Richard Pryor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some of them motherfuckers with a little but them right there. Shit. That’s what I mean? You go out there and shit. When you say, “No. Motherfucker doin’ my dick was on the shit them motherfuckers was on the country, right? I like to me. I don’t know what I mean? They got the boy to get the shit on the black me. I ain’t gonna be some fun. I was doing there and shit. Why don’t you say, “Feel the shit on the bean. I said, “I ain’t gonna start talking about my man. I said, ”Boy, they got the shit. I was on the thing. I’m gonna be in the toilet, man. I said, ”Boy, they’re going to see the shit the shit the fuck all the thing. I’m gonna take them motherfucker lady. So I ain’t gonna say. “Fuck you. And you know what I mean? Something to your shit. You know, say, ”We’re not going to see this on the car. And stalk something in the toilet on the thing to me. I don’t know what I mean? So I can’t get it to the house. When you doin’? I was sitting on the back. They don’t go out in the triest to see the shit. I had a pistol. You know, this is the left fuckin’ around. They don’t know where I got a little motherfuckers. I mean, it was you in the real something with me… and shit, they’re gonna be like anything to me. I don’t know what I mean? You know. I don’t know when you say, “I ain’t gonna be in the motherfuckers. She gonna get to me. I don’t know what I mean? I was one of them brothers with a bitch. You know what I mean? Shit, yeah. I’m gonna take my ass. I was not fucking around and shit. And you see the man that shit out of them motherfuckers some bust be friends and shit. You know what I mean? You know what I mean? Shit. I got a little while. You know what I mean?” I said, “Don’t wash me. I’m gonna see this on your shit. When I was a precking them to be back to see that shit in America store. You know, it got the shit out of me. I was nothin’ to the back here. You know. You know, when the shit the fuck all the shit in the toilet. And they say a little kid a child ass of your \n"
     ]
    }
   ],
   "source": [
    "text = open(rpryor_path, 'rb').read().decode(encoding = \"utf-8\")\n",
    "vocab = sorted(set(text))\n",
    "\n",
    "\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])\n",
    "\n",
    "#Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension \n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024\n",
    "\n",
    "\n",
    "#Build and load model\n",
    "rpryor_model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "rpryor_model.load_weights(tf.train.latest_checkpoint('./rpryor_training'))\n",
    "\n",
    "rpryor_model.build(tf.TensorShape([1, None]))\n",
    "\n",
    "\n",
    "print(generate_text(rpryor_model, start_string=u\"So\",temperature=.35))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anthony Jeselnik "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sond they say, \"Anthony, I got a bad performing about that joke is in the world.\n",
      "It was should just for me. I didn’t know it come up the things on me.\n",
      "The says, “Anthony, that joke is funny. I was a kid, my grandmather doesn’t make me the first time I mean, that joke is all were really fucking done.\n",
      "\n",
      "I was a good to come and me a prople with me over in the worldred it on me.\n",
      "Like a see that.\n",
      "The once mean it the bad respocking to her about it.\n",
      "I said, “Los, I was gonna be a proute the back of the world. I was a kid, my mom’s but her and getting probably mind of the show, but the worst thing I’m a bad pering my shows.\n",
      "\n",
      "The one with me as it.\n",
      "I said, “What the worst that makes me way and getsing to my life was a bad performing in the world. Yeah. Like, the best care and getting out of the worst don't think I’m about that manther. She said, “Anthony, you know, I have a problem mind of the things to the worst going to the comedian this cousing an abortion clinic. I might because the first time I say, \"Anthony, you know? I have to me.\n",
      "\n",
      "And I said, “Anthony, it’s okay. I don’t know if you guys are gonna be a proute that I get me a priend the worst the ent of the shit out of the world.\n",
      "I love it would have it.\n",
      "But I was a kid. How money to the comedian comedian sonething I’ve ever here around to hear the worst to be a really have me the for the modern a house in the worst give you a baby in the world.\n",
      "It was gonna tell you think it’s a fucking things good. She was a great friends and my grandma had a bad performing about my dad happened a bad person and get in the world.\n",
      "I say that I say to tell your friends was a kid, my dourd and they always say, “Anthony, this weeks ago, but the could to tell you a money.\n",
      "I was going to me. I was a kid, my grandma had a bad to me.\n",
      "And they say, “Anthony, that’s a funcher in the world.\n",
      "I love it on me.\n",
      "I say, “Anthony, I had a bad to me the world.\n",
      "I said, “Hey, where is a big fun. And my grandmather doesn’t say, “Anthony, what harg to me.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = open(ajesel_path, 'rb').read().decode(encoding = \"utf-8\")\n",
    "vocab = sorted(set(text))\n",
    "\n",
    "\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])\n",
    "\n",
    "#Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension \n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024\n",
    "\n",
    "\n",
    "#Build and load model\n",
    "ajesel_model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "ajesel_model.load_weights(tf.train.latest_checkpoint('./ajesel_training'))\n",
    "\n",
    "ajesel_model.build(tf.TensorShape([1, None]))\n",
    "\n",
    "print(generate_text(ajesel_model, start_string=u\"So\",temperature=.35))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load AllCom model (trained on various comedians) and generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So fuck. They never fuck with that methadone, man? That shit was ridiculous. The strangest thing in my machine. I don’t know what you want to do to him.” You know? I get fingered and I’m like, “no, no, I don’t.” She’s like, “no, he’s still giving Ked eate it.” Yeah, she’s done that. She got a different kind. Shit, he must be from Brazil or someport come from?” And then I just started talkin’ about… “All right. Give me the money when you get a snget. I got some shit they didn’t see it! All right? Let me get a whole thing. Twenty person in the real shit from time to take a while, and I was like, “Yeah, you know, like, if they fuck all your impression of who said, “Anthony, I wanna know. Like, wh-why is it… why is it that… that I can say the superintendent of the other side.” “But over here, there stood up in the bushes all night and shit. He’s goin’. “Goddamn!” He didn’t know what to say. He asked it. I have no more money laying a dog research. Went even deeper into this bitch today. Far do the car. It’s so many times. Like, I don’t want this in me, either.” It’s just a… Balls are just a crock pot for the red stick. You see this shit to stop.” Crackheads are like, “Oh, I said, ”Bitch, that’s right. I went to this party. All the old ladies there were unbelievably sharp. They were still so prond it is,Jack. Hey, speak to me!” Like, if that’s what it feels like, hooking up when I was 15, my dick was hard all the time, the only dry humping. Man, I got some controversial, you could say, “Like, it’s… I don’t know, maybe in Atlanta might be crazy. And I was like, “Oh, my God, it’s the worst motherfuckers. And I got a dog, I mean… You know, if I’m lucky, you can be. But the second she says, like, “I don’t know, maybe in Aurora. We had a great lawyer who kick a baby’s cute, say– ”Hey, I am was the greatest dude I ever met. Just bring him home. “Have a seat, if they would make a couple stuff. I’m like, “I have to be the designs to right be horrible. Does she think that I don’t tr\n"
     ]
    }
   ],
   "source": [
    "text = open(allcom_path, 'rb').read().decode(encoding = \"utf-8\")\n",
    "vocab = sorted(set(text))\n",
    "\n",
    "\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])\n",
    "\n",
    "#Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension \n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024\n",
    "\n",
    "\n",
    "#Build and load model\n",
    "allcom_model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "allcom_model.load_weights(tf.train.latest_checkpoint('./allcom_training'))\n",
    "\n",
    "allcom_model.build(tf.TensorShape([1, None]))\n",
    "\n",
    "print(generate_text(allcom_model, start_string=u\"So\",temperature=.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
